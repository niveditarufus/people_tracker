{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3348fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "from torch import linalg\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e022f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_file):\n",
    "    img = cv2.imread(image_file, cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Failed to read {}\".format(image_file))\n",
    "    return img\n",
    "\n",
    "class IRPeople(data.Dataset):\n",
    "    def __init__(self, root, annotation_file, transforms):\n",
    "        self.root = root\n",
    "        print(annotation_file)\n",
    "        self.imlist = pd.read_csv(annotation_file)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cv2.setNumThreads(6)\n",
    "\n",
    "        impath, target= self.imlist.iloc[index]\n",
    "        impath = impath.split('/')[-1].strip()\n",
    "\n",
    "        full_imname = os.path.join(self.root, impath)\n",
    "        img = read_image(full_imname)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imlist)\n",
    "    \n",
    "def get_train_aug():\n",
    "    train_augs = tv.transforms.Compose(\n",
    "        [\n",
    "            tv.transforms.Resize((224, 224)),\n",
    "            tv.transforms.RandomVerticalFlip(),\n",
    "            tv.transforms.RandomHorizontalFlip(),\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize(\n",
    "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                std=[0.26862954, 0.26130258, 0.27577711],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return train_augs\n",
    "\n",
    "def get_dataloaders():\n",
    "    print(\"Preparing train reader...\")\n",
    "    train_dataset = IRPeople(\n",
    "        root=os.path.join('./images', \"train\"),\n",
    "        annotation_file=os.path.join('./images', 'annotations.csv'),\n",
    "        transforms=get_train_aug(),\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2619b551",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:14\u001b[0;36m\u001b[0m\n\u001b[0;31m    def update(self, c_epoch):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class ArcFace(nn.Module):\n",
    "def __init__(self, cin, cout, s=30, m=0.5, stride=0.1, max_m=0.8):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        self.sin_m = torch.sin(torch.tensor(self.m))\n",
    "        self.cos_m = torch.cos(torch.tensor(self.m))\n",
    "        self.cout = cout\n",
    "        self.fc = nn.Linear(cin, cout, bias=False)\n",
    "        self.last_epoch = 0\n",
    "        self.max_m = max_m\n",
    "        self.m_s = stride\n",
    "\n",
    "    def update(self, c_epoch):\n",
    "        self.m = min(self.m + self.m_s * (c_epoch - self.last_epoch), self.max_m)\n",
    "        self.last_epoch = c_epoch\n",
    "        self.sin_m = torch.sin(torch.tensor(self.m))\n",
    "        self.cos_m = torch.cos(torch.tensor(self.m))\n",
    "\n",
    "    def forward(self, x, label=None):\n",
    "        w_L2 = linalg.norm(self.fc.weight.detach(), dim=1, keepdim=True).T\n",
    "        x_L2 = linalg.norm(x, dim=1, keepdim=True)\n",
    "        cos = self.fc(x) / (x_L2 * w_L2)\n",
    "        if label is not None:\n",
    "            sin_m, cos_m = self.sin_m, self.cos_m\n",
    "            one_hot = F.one_hot(label, num_classes=self.cout)\n",
    "            sin = (1 - cos**2) ** 0.5\n",
    "            angle_sum = cos * cos_m - sin * sin_m\n",
    "            cos = angle_sum * one_hot + cos * (1 - one_hot)\n",
    "            cos = cos * self.s\n",
    "        return cos\n",
    "\n",
    "class Classifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier_model, self).__init__()\n",
    "        self.model = tv.models.resnet50(pretrained=True)\n",
    "        state_dict_model = torch.load(\"../model/ft_ResNet50/net_last.pth\")\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict_model.items():\n",
    "            if \"model.\" in k:\n",
    "                name = k.replace(\"model.\", \"\", 1)\n",
    "                new_state_dict[name] = v\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "        self.fc = ArcFace(\n",
    "            1000,\n",
    "            9,\n",
    "            s=30,\n",
    "            m=0.3,\n",
    "            stride=0.05,\n",
    "            max_m=0.8,\n",
    "        )\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.model(x)\n",
    "        x = self.fc(x, labels)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRPeopleModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Classifier_model()\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        return self.model(img, labels)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = [\n",
    "            {\"params\": self.model.model.parameters(), \"lr\": 1e-5},\n",
    "            {\"params\": self.model.fc.parameters(), \"lr\": 1e-3},\n",
    "        ]\n",
    "        self.optimizer = torch.optim.AdamW(params, weight_decay=1e-2)\n",
    "        return [self.optimizer]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, labels = batch\n",
    "        preds = self.model(img, labels)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.model.fc.update(self.current_epoch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=False)\n",
    "        return loss  # Return tensor to call \".backward\" on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add08300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luffy/miniconda3/envs/tracker/lib/python3.10/site-packages/lightning_fabric/connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train reader...\n",
      "./images/annotations.csv\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luffy/miniconda3/envs/tracker/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/luffy/miniconda3/envs/tracker/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/luffy/workspace/people_tracker/reid/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | Classifier_model | 25.6 M\n",
      "1 | loss_module | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.264   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▌        | 96/614 [00:04<00:25, 20.53it/s, v_num=0, train_acc_step=0.938, train_acc_epoch=0.843] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luffy/miniconda3/envs/tracker/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "train_loader= get_dataloaders()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    precision=16,\n",
    "    devices=[0],\n",
    ")\n",
    "model = IRPeopleModule()\n",
    "trainer.fit(model, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
